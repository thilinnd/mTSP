{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "class meax_mtsp:\n",
    "    def __init__(self, distance_matrix: np.ndarray, m: int = 3,\n",
    "                 pop_size: int = 10, generations: int = 30):\n",
    "        \n",
    "        self.distance_matrix = np.asarray(distance_matrix)\n",
    "        self.m = int(m)\n",
    "        self.pop_size = int(pop_size)\n",
    "        self.generations = int(generations)\n",
    "        self._n = self.distance_matrix.shape[0]\n",
    "        # cache cho fitness: key = tuple(permutation)\n",
    "        self._fitness_cache = {}\n",
    "\n",
    "        # Các tham số điều chỉnh tốc độ/chiến lược (có thể chỉnh)\n",
    "        self._pc = 0.8              # crossover probability (hard-coded)\n",
    "        self._two_opt_j_span = 50   # giới hạn j-range khi thử 2-opt (độ rộng)\n",
    "        self._vnd_sample_moves = 80 # số lượng move sampled per neighborhood (thay cho exhaustive)\n",
    "        self._vnd_max_iters = 60    # tổng số vòng kiểm tra neighborhoods trong VND\n",
    "\n",
    "    # ---------------- helpers ----------------\n",
    "    def _perm_key(self, perm: List[int]) -> Tuple[int]:\n",
    "        return tuple(perm)\n",
    "\n",
    "    def _route_distance(self, route: List[int]) -> float:\n",
    "        \"\"\"Tính khoảng cách của 1 route bắt đầu/ending tại depot(0).\n",
    "           Dùng numpy indexing cho tốc độ.\"\"\"\n",
    "        if not route:\n",
    "            return 0.0\n",
    "        arr = [0] + route + [0]\n",
    "        prevs = np.array(arr[:-1], dtype=int)\n",
    "        nexts = np.array(arr[1:], dtype=int)\n",
    "        return float(self.distance_matrix[prevs, nexts].sum())\n",
    "\n",
    "    # ---------------- Step 1: Initialization ----------------\n",
    "    def initialize_population(self) -> List[List[int]]:\n",
    "        cities = list(range(1, self._n))\n",
    "        return [random.sample(cities, len(cities)) for _ in range(self.pop_size)]\n",
    "\n",
    "    # ---------------- Decode and perm helpers ----------------\n",
    "    def decode_solution(self, chromosome: List[int]) -> List[List[int]]:\n",
    "        routes = [[] for _ in range(self.m)]\n",
    "        for i, city in enumerate(chromosome):\n",
    "            routes[i % self.m].append(city)\n",
    "        return routes\n",
    "\n",
    "    def perm_from_routes(self, routes: List[List[int]]) -> List[int]:\n",
    "        idxs = [0] * len(routes)\n",
    "        perm = []\n",
    "        while True:\n",
    "            added = False\n",
    "            for r in range(len(routes)):\n",
    "                if idxs[r] < len(routes[r]):\n",
    "                    perm.append(routes[r][idxs[r]])\n",
    "                    idxs[r] += 1\n",
    "                    added = True\n",
    "            if not added:\n",
    "                break\n",
    "        # append missing (safety)\n",
    "        all_cities = set(range(1, self._n))\n",
    "        if set(perm) != all_cities:\n",
    "            for c in range(1, self._n):\n",
    "                if c not in perm:\n",
    "                    perm.append(c)\n",
    "        return perm\n",
    "\n",
    "    # ---------------- Step 2: Fitness with caching ----------------\n",
    "    def calculate_fitness(self, chromosome: List[int]) -> float:\n",
    "        key = self._perm_key(chromosome)\n",
    "        v = self._fitness_cache.get(key)\n",
    "        if v is not None:\n",
    "            return v\n",
    "        # compute max route distance (vectorized per route)\n",
    "        routes = self.decode_solution(chromosome)\n",
    "        maxd = 0.0\n",
    "        for r in routes:\n",
    "            d = self._route_distance(r)\n",
    "            if d > maxd:\n",
    "                maxd = d\n",
    "        self._fitness_cache[key] = maxd\n",
    "        return maxd\n",
    "\n",
    "    # ---------------- mEAX crossover (kept name mEAX_crossover) ----------------\n",
    "    def mEAX_crossover(self, p1: List[int], p2: List[int]) -> Tuple[List[int], List[int]]:\n",
    "        if random.random() > self._pc:\n",
    "            return p1.copy(), p2.copy()\n",
    "\n",
    "        def edges_from_perm(perm):\n",
    "            edges = set()\n",
    "            size = len(perm)\n",
    "            for i in range(size):\n",
    "                a = perm[i]; b = perm[(i + 1) % size]\n",
    "                edges.add((min(a, b), max(a, b)))\n",
    "            return edges\n",
    "\n",
    "        A_edges = edges_from_perm(p1)\n",
    "        B_edges = edges_from_perm(p2)\n",
    "\n",
    "        edge_label = {}\n",
    "        for e in A_edges:\n",
    "            edge_label.setdefault(e, set()).add('A')\n",
    "        for e in B_edges:\n",
    "            edge_label.setdefault(e, set()).add('B')\n",
    "\n",
    "        adj_A = defaultdict(list)\n",
    "        adj_B = defaultdict(list)\n",
    "        for (u, v) in A_edges:\n",
    "            adj_A[u].append(v); adj_A[v].append(u)\n",
    "        for (u, v) in B_edges:\n",
    "            adj_B[u].append(v); adj_B[v].append(u)\n",
    "\n",
    "        all_edges = set(edge_label.keys())\n",
    "        used_edge = set()\n",
    "        AB_cycles = []\n",
    "\n",
    "        # build AB-cycles (alternate A/B) — use random tie-breaking to avoid worstcase determinism\n",
    "        while True:\n",
    "            unused = [e for e in all_edges if e not in used_edge]\n",
    "            if not unused:\n",
    "                break\n",
    "            start_edge = unused[0]\n",
    "            cycle = []\n",
    "            u0, v0 = start_edge\n",
    "            current_node = u0\n",
    "            prev_edge = start_edge\n",
    "            next_label = 'B' if 'A' in edge_label[start_edge] else 'A'\n",
    "            cycle.append(prev_edge)\n",
    "            used_edge.add(prev_edge)\n",
    "            while True:\n",
    "                a, b = prev_edge\n",
    "                current_node = b if current_node == a else a\n",
    "                candidate_edges = []\n",
    "                if next_label == 'A':\n",
    "                    for nb in adj_A[current_node]:\n",
    "                        edge = (min(current_node, nb), max(current_node, nb))\n",
    "                        if edge not in used_edge:\n",
    "                            candidate_edges.append(edge)\n",
    "                else:\n",
    "                    for nb in adj_B[current_node]:\n",
    "                        edge = (min(current_node, nb), max(current_node, nb))\n",
    "                        if edge not in used_edge:\n",
    "                            candidate_edges.append(edge)\n",
    "                if not candidate_edges:\n",
    "                    break\n",
    "                # pick random candidate to reduce bias and runtime patterns\n",
    "                next_edge = random.choice(candidate_edges)\n",
    "                cycle.append(next_edge)\n",
    "                used_edge.add(next_edge)\n",
    "                prev_edge = next_edge\n",
    "                next_label = 'A' if next_label == 'B' else 'B'\n",
    "                if prev_edge == start_edge:\n",
    "                    break\n",
    "            if cycle:\n",
    "                AB_cycles.append(cycle)\n",
    "\n",
    "        # fallback simple OX if no cycles found\n",
    "        if not AB_cycles:\n",
    "            size = len(p1)\n",
    "            a, b = sorted(random.sample(range(size), 2))\n",
    "            def ox(pA, pB):\n",
    "                child = [None]*size\n",
    "                child[a:b] = pA[a:b]\n",
    "                pos = b\n",
    "                for city in pB[b:] + pB[:b]:\n",
    "                    if city not in child:\n",
    "                        if pos >= size:\n",
    "                            pos = 0\n",
    "                        child[pos] = city\n",
    "                        pos += 1\n",
    "                return child\n",
    "            return ox(p1, p2), ox(p2, p1)\n",
    "\n",
    "        cycles_idx = list(range(len(AB_cycles)))\n",
    "        sel1 = set(i for i in cycles_idx if random.random() < 0.5)\n",
    "        if not sel1:\n",
    "            sel1.add(random.choice(cycles_idx))\n",
    "        sel2 = set(i for i in cycles_idx if random.random() < 0.5)\n",
    "        if not sel2:\n",
    "            sel2.add(random.choice(cycles_idx))\n",
    "\n",
    "        def build_child_edges(selected_idx_set, base_edges):\n",
    "            child_edges = set(base_edges)\n",
    "            for i in selected_idx_set:\n",
    "                for e in AB_cycles[i]:\n",
    "                    if e in child_edges:\n",
    "                        child_edges.remove(e)\n",
    "                    else:\n",
    "                        child_edges.add(e)\n",
    "            return child_edges\n",
    "\n",
    "        child1_edges = build_child_edges(sel1, A_edges)\n",
    "        child2_edges = build_child_edges(sel2, A_edges)\n",
    "\n",
    "        def edges_to_cycles(edge_set):\n",
    "            adj = defaultdict(list)\n",
    "            for (u, v) in edge_set:\n",
    "                adj[u].append(v); adj[v].append(u)\n",
    "            cycles = []\n",
    "            visited = set()\n",
    "            for node in adj:\n",
    "                if node in visited:\n",
    "                    continue\n",
    "                curr = node; prev = None; seq = []\n",
    "                while True:\n",
    "                    seq.append(curr)\n",
    "                    visited.add(curr)\n",
    "                    nbrs = adj[curr]\n",
    "                    if not nbrs:\n",
    "                        break\n",
    "                    next_node = None\n",
    "                    if len(nbrs) == 1:\n",
    "                        next_node = nbrs[0]\n",
    "                    else:\n",
    "                        next_node = nbrs[0] if nbrs[0] != prev else nbrs[1]\n",
    "                    prev, curr = curr, next_node\n",
    "                    if curr == node or curr is None:\n",
    "                        break\n",
    "                if seq:\n",
    "                    cycles.append(seq)\n",
    "            return cycles\n",
    "\n",
    "        cycles1 = edges_to_cycles(child1_edges)\n",
    "        cycles2 = edges_to_cycles(child2_edges)\n",
    "\n",
    "        def stitch_cycles(cycles):\n",
    "            if not cycles:\n",
    "                return []\n",
    "            seqs = [c.copy() for c in cycles]\n",
    "            seqs.sort(key=lambda s: -len(s))\n",
    "            perm = seqs[0].copy()\n",
    "            remaining = seqs[1:]\n",
    "            while remaining:\n",
    "                best_idx = None; best_cost = float('inf'); best_orient = False\n",
    "                for i, s in enumerate(remaining):\n",
    "                    # compute only two seam costs\n",
    "                    cost1 = self.distance_matrix[perm[-1]][s[0]]\n",
    "                    cost2 = self.distance_matrix[perm[-1]][s[-1]]\n",
    "                    if cost1 < best_cost:\n",
    "                        best_cost = cost1; best_idx = i; best_orient = False\n",
    "                    if cost2 < best_cost:\n",
    "                        best_cost = cost2; best_idx = i; best_orient = True\n",
    "                s = remaining.pop(best_idx)\n",
    "                if best_orient:\n",
    "                    s = s[::-1]\n",
    "                perm.extend(s)\n",
    "            # append missing\n",
    "            all_cities = set(range(1, self._n))\n",
    "            missing = list(all_cities - set(perm))\n",
    "            if missing:\n",
    "                perm.extend(missing)\n",
    "            return perm\n",
    "\n",
    "        perm1 = stitch_cycles(cycles1)\n",
    "        perm2 = stitch_cycles(cycles2)\n",
    "\n",
    "        # limited 2-opt repair (restricted j-range and iterations)\n",
    "        def two_opt_local(perm, max_iters=80):\n",
    "            best = perm\n",
    "            best_fit = self.calculate_fitness(best)\n",
    "            n = len(perm)\n",
    "            it = 0\n",
    "            improved = True\n",
    "            while it < max_iters and improved:\n",
    "                improved = False\n",
    "                # sample some (i,j) pairs rather than exhaustive\n",
    "                sample_pairs = min(200, n * 5)\n",
    "                for _ in range(sample_pairs):\n",
    "                    i = random.randrange(0, n - 2)\n",
    "                    j = random.randrange(i + 2, min(n, i + 2 + self._two_opt_j_span))\n",
    "                    new = best[:i+1] + best[i+1:j+1][::-1] + best[j+1:]\n",
    "                    new_fit = self.calculate_fitness(new)\n",
    "                    if new_fit + 1e-12 < best_fit:\n",
    "                        best = new; best_fit = new_fit; improved = True; break\n",
    "                it += 1\n",
    "            return best\n",
    "\n",
    "        perm1 = two_opt_local(perm1, max_iters=60)\n",
    "        perm2 = two_opt_local(perm2, max_iters=60)\n",
    "\n",
    "        # validate perms\n",
    "        def validate_perm(perm):\n",
    "            all_cities = set(range(1, self._n))\n",
    "            if set(perm) != all_cities or len(perm) != len(all_cities):\n",
    "                seen = set(); new = []\n",
    "                for x in perm:\n",
    "                    if x not in seen and 1 <= x < self._n:\n",
    "                        new.append(x); seen.add(x)\n",
    "                for x in range(1, self._n):\n",
    "                    if x not in seen:\n",
    "                        new.append(x); seen.add(x)\n",
    "                return new\n",
    "            return perm\n",
    "\n",
    "        perm1 = validate_perm(perm1)\n",
    "        perm2 = validate_perm(perm2)\n",
    "        return perm1, perm2\n",
    "\n",
    "    # ---------------- VND (lightweight with sampling & local delta) ----------------\n",
    "    def vnd_improvement(self, chromosome: List[int], max_iters: int = None) -> List[int]:\n",
    "        if max_iters is None:\n",
    "            max_iters = self._vnd_max_iters\n",
    "        current = chromosome.copy()\n",
    "        current_fit = self.calculate_fitness(current)\n",
    "\n",
    "        neighborhoods = ['2opt', 'relocate', 'swap']\n",
    "        k = 0\n",
    "        it = 0\n",
    "        while it < max_iters and k < len(neighborhoods):\n",
    "            improved = False\n",
    "            routes = self.decode_solution(current)\n",
    "\n",
    "            # 1) intra-route 2-opt (sampled)\n",
    "            if neighborhoods[k] == '2opt':\n",
    "                best_perm = current; best_fit = current_fit\n",
    "                # sample up to S moves across all routes\n",
    "                S = self._vnd_sample_moves\n",
    "                for _ in range(S):\n",
    "                    # select route with prob proportional to length (longer routes more likely)\n",
    "                    lens = [len(r) for r in routes]\n",
    "                    if sum(lens) == 0:\n",
    "                        break\n",
    "                    idx = random.choices(range(len(routes)), weights=[l+1 for l in lens], k=1)[0]\n",
    "                    r = routes[idx]\n",
    "                    lr = len(r)\n",
    "                    if lr < 4:\n",
    "                        continue\n",
    "                    i = random.randrange(0, lr - 2)\n",
    "                    j = random.randrange(i + 1, min(lr, i + 1 + self._two_opt_j_span))\n",
    "                    # compute route-level delta: old_distance and new_distance\n",
    "                    old_dist = self._route_distance(r)\n",
    "                    new_r = r[:i+1] + r[i+1:j+1][::-1] + r[j+1:]\n",
    "                    new_dist = self._route_distance(new_r)\n",
    "                    if new_dist < old_dist - 1e-12:\n",
    "                        # apply change\n",
    "                        new_routes = [list(rr) for rr in routes]\n",
    "                        new_routes[idx] = new_r\n",
    "                        new_perm = self.perm_from_routes(new_routes)\n",
    "                        new_fit = max(current_fit, new_dist) if old_dist < current_fit else self.calculate_fitness(new_perm)\n",
    "                        # safer: compute full fitness (but only when promising) -> we compute full fitness to be accurate\n",
    "                        new_fit = self.calculate_fitness(new_perm)\n",
    "                        if new_fit + 1e-12 < best_fit:\n",
    "                            best_fit = new_fit; best_perm = new_perm; improved = True; break\n",
    "                if improved:\n",
    "                    current = best_perm; current_fit = best_fit; k = 0\n",
    "\n",
    "            # 2) relocate (sampled moves)\n",
    "            elif neighborhoods[k] == 'relocate':\n",
    "                best_perm = current; best_fit = current_fit\n",
    "                S = self._vnd_sample_moves\n",
    "                # target moves from longer routes\n",
    "                r_dists = [self._route_distance(r) for r in routes]\n",
    "                order_src = sorted(range(len(routes)), key=lambda x: -r_dists[x])\n",
    "                tries = 0\n",
    "                while tries < S:\n",
    "                    if not order_src:\n",
    "                        break\n",
    "                    src = random.choice(order_src[:min(len(order_src), 3)])\n",
    "                    if not routes[src]:\n",
    "                        tries += 1; continue\n",
    "                    pos = random.randrange(0, len(routes[src]))\n",
    "                    city = routes[src][pos]\n",
    "                    dst = random.randrange(0, len(routes))\n",
    "                    if dst == src:\n",
    "                        tries += 1; continue\n",
    "                    insert_pos = random.randrange(0, len(routes[dst]) + 1)\n",
    "                    new_routes = [list(rr) for rr in routes]\n",
    "                    new_routes[src].pop(pos)\n",
    "                    new_routes[dst].insert(insert_pos, city)\n",
    "                    new_perm = self.perm_from_routes(new_routes)\n",
    "                    new_fit = self.calculate_fitness(new_perm)\n",
    "                    if new_fit + 1e-12 < best_fit:\n",
    "                        best_fit = new_fit; best_perm = new_perm; improved = True; break\n",
    "                    tries += 1\n",
    "                if improved:\n",
    "                    current = best_perm; current_fit = best_fit; k = 0\n",
    "\n",
    "            # 3) swap (sampled)\n",
    "            elif neighborhoods[k] == 'swap':\n",
    "                best_perm = current; best_fit = current_fit\n",
    "                S = self._vnd_sample_moves\n",
    "                tries = 0\n",
    "                # pick from top 3 routes by distance to focus on problematic routes\n",
    "                r_dists = [self._route_distance(r) for r in routes]\n",
    "                top_routes = sorted(range(len(routes)), key=lambda x: -r_dists[x])[:min(3, len(routes))]\n",
    "                while tries < S:\n",
    "                    if len(top_routes) < 2:\n",
    "                        break\n",
    "                    i_idx, j_idx = random.sample(top_routes, 2)\n",
    "                    if not routes[i_idx] or not routes[j_idx]:\n",
    "                        tries += 1; continue\n",
    "                    a = random.randrange(0, len(routes[i_idx]))\n",
    "                    b = random.randrange(0, len(routes[j_idx]))\n",
    "                    new_routes = [list(rr) for rr in routes]\n",
    "                    new_routes[i_idx][a], new_routes[j_idx][b] = new_routes[j_idx][b], new_routes[i_idx][a]\n",
    "                    new_perm = self.perm_from_routes(new_routes)\n",
    "                    new_fit = self.calculate_fitness(new_perm)\n",
    "                    if new_fit + 1e-12 < best_fit:\n",
    "                        best_fit = new_fit; best_perm = new_perm; improved = True; break\n",
    "                    tries += 1\n",
    "                if improved:\n",
    "                    current = best_perm; current_fit = best_fit; k = 0\n",
    "\n",
    "            if not improved:\n",
    "                k += 1\n",
    "            it += 1\n",
    "\n",
    "        return current\n",
    "\n",
    "    # ---------------- Step 5: Main Loop ----------------\n",
    "    def run(self):\n",
    "        # clear cache at start\n",
    "        self._fitness_cache.clear()\n",
    "        population = self.initialize_population()\n",
    "        best_solution = None\n",
    "        best_fitness = float('inf')\n",
    "        fitness_history = []\n",
    "\n",
    "        # pre-evaluate initial pop (and cache)\n",
    "        pop_fitness = [self.calculate_fitness(ind) for ind in population]\n",
    "\n",
    "        for gen in range(self.generations):\n",
    "            # track best\n",
    "            min_idx = int(np.argmin(pop_fitness))\n",
    "            if pop_fitness[min_idx] < best_fitness:\n",
    "                best_fitness = pop_fitness[min_idx]\n",
    "                best_solution = population[min_idx].copy()\n",
    "\n",
    "            offspring = []\n",
    "            # produce offspring until fill (random parent selection as in paper)\n",
    "            while len(offspring) < self.pop_size:\n",
    "                p1 = random.choice(population)\n",
    "                p2 = random.choice(population)\n",
    "                if p1 == p2:\n",
    "                    p2 = random.choice(population)\n",
    "                c1, c2 = self.mEAX_crossover(p1, p2)\n",
    "                # local search VND (lightweight)\n",
    "                c1 = self.vnd_improvement(c1, max_iters=30)\n",
    "                c2 = self.vnd_improvement(c2, max_iters=30)\n",
    "                offspring.append(c1)\n",
    "                offspring.append(c2)\n",
    "\n",
    "            # combine and select best pop_size\n",
    "            combined = population + offspring\n",
    "            # compute/lookup fitness for combined\n",
    "            combined_fitness = [self.calculate_fitness(ind) for ind in combined]\n",
    "            sorted_idx = np.argsort(combined_fitness)\n",
    "            selected_idx = sorted_idx[:self.pop_size]\n",
    "            population = [combined[i] for i in selected_idx]\n",
    "            pop_fitness = [combined_fitness[i] for i in selected_idx]\n",
    "\n",
    "            fitness_history.append(best_fitness)\n",
    "            if gen % 1 == 0:\n",
    "                print(f\"Gen {gen}: Best max route length = {best_fitness:.4f}\")\n",
    "\n",
    "        # final metrics\n",
    "        routes = self.decode_solution(best_solution)\n",
    "        route_distances = [self._route_distance(r) for r in routes]\n",
    "        total_distance = sum(route_distances)\n",
    "        balance_metric = max(route_distances) - min(route_distances) if route_distances else 0.0\n",
    "        return routes, total_distance, best_fitness, balance_metric, fitness_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số thành phố: 127\n",
      "Ví dụ khoảng cách [0][1]: 21.48\n"
     ]
    }
   ],
   "source": [
    "distance_df = pd.read_csv(r'..\\data\\HN_distance_matrix.csv', index_col=0)\n",
    "distance_matrix = distance_df.values\n",
    "\n",
    "# Kiểm tra sơ bộ\n",
    "print(\"Số thành phố:\", distance_matrix.shape[0])\n",
    "print(\"Ví dụ khoảng cách [0][1]:\", distance_matrix[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_convergence(generation_fitness, tolerance=1e-3, window=5):\n",
    "    for i in range(len(generation_fitness) - window):\n",
    "        window_values = generation_fitness[i:i+window]\n",
    "        if max(window_values) - min(window_values) < tolerance:\n",
    "            return i + window\n",
    "    print(f\"Không phát hiện hội tụ sớm — thuật toán chạy đủ {len(generation_fitness)} thế hệ.\")\n",
    "    return len(generation_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MEAX - Số người bán hàng (m) = 1 ===\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m MEAX \u001b[38;5;241m=\u001b[39m meax_mtsp(distance_matrix, m\u001b[38;5;241m=\u001b[39mm, pop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m routes, total_distance, max_route, balance_metric, fitness_per_generation \u001b[38;5;241m=\u001b[39m \u001b[43mMEAX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m exec_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[1], line 443\u001b[0m, in \u001b[0;36mmeax_mtsp.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p1 \u001b[38;5;241m==\u001b[39m p2:\n\u001b[0;32m    442\u001b[0m     p2 \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(population)\n\u001b[1;32m--> 443\u001b[0m c1, c2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmEAX_crossover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# local search VND (lightweight)\u001b[39;00m\n\u001b[0;32m    445\u001b[0m c1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvnd_improvement(c1, max_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 230\u001b[0m, in \u001b[0;36mmeax_mtsp.mEAX_crossover\u001b[1;34m(self, p1, p2)\u001b[0m\n\u001b[0;32m    227\u001b[0m             cycles\u001b[38;5;241m.\u001b[39mappend(seq)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cycles\n\u001b[1;32m--> 230\u001b[0m cycles1 \u001b[38;5;241m=\u001b[39m \u001b[43medges_to_cycles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild1_edges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m cycles2 \u001b[38;5;241m=\u001b[39m edges_to_cycles(child2_edges)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstitch_cycles\u001b[39m(cycles):\n",
      "Cell \u001b[1;32mIn[1], line 213\u001b[0m, in \u001b[0;36mmeax_mtsp.mEAX_crossover.<locals>.edges_to_cycles\u001b[1;34m(edge_set)\u001b[0m\n\u001b[0;32m    211\u001b[0m curr \u001b[38;5;241m=\u001b[39m node; prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m; seq \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     visited\u001b[38;5;241m.\u001b[39madd(curr)\n\u001b[0;32m    215\u001b[0m     nbrs \u001b[38;5;241m=\u001b[39m adj[curr]\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Run experiments for different numbers of salesmen\n",
    "for m in range(1, 4):\n",
    "    print(f\"\\n=== MEAX - Số người bán hàng (m) = {m} ===\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    MEAX = meax_mtsp(distance_matrix, m=m, pop_size=10, generations=30)\n",
    "    routes, total_distance, max_route, balance_metric, fitness_per_generation = MEAX.run()\n",
    "\n",
    "    end_time = time.time()\n",
    "    exec_time = end_time - start_time\n",
    "\n",
    "    route_distances = []\n",
    "    for route in routes:\n",
    "        if len(route) > 0:\n",
    "            full_route = [0] + route + [0]\n",
    "            distance = sum(distance_matrix[full_route[i]][full_route[i+1]] \n",
    "                           for i in range(len(full_route)-1))\n",
    "            route_distances.append(distance)\n",
    "        else:\n",
    "            route_distances.append(0)\n",
    "\n",
    "    balance_metric = max(route_distances) - min(route_distances) if route_distances else 0\n",
    "\n",
    "    # Convergence analysis\n",
    "    converged_gen = detect_convergence(fitness_per_generation)\n",
    "    convergence_speed = (fitness_per_generation[0] - fitness_per_generation[-1]) / converged_gen if converged_gen > 0 else 0\n",
    "\n",
    "    # Print results - all required metrics\n",
    "    print(f\"Tổng quãng đường: {total_distance:.2f}\")\n",
    "    print(f\"Chiều dài route dài nhất (Max route length): {max_route:.2f}\")\n",
    "    print(f\"Chênh lệch giữa các route (Balance metric): {balance_metric:.2f}\")\n",
    "    print(f\"Thời gian thực thi: {exec_time:.4f} giây\")\n",
    "    print(f\"Số vòng lặp cần thiết để hội tụ: {converged_gen}\")\n",
    "    print(f\"Tốc độ hội tụ: {convergence_speed:.4f} đơn vị/gen\")\n",
    "\n",
    "    # Display individual routes\n",
    "    for i, route in enumerate(routes):\n",
    "        if len(route) > 0:\n",
    "            full_route = [0] + route + [0]\n",
    "            print(f\" - Tuyến {i+1} ({route_distances[i]:.2f}): {full_route}\")\n",
    "        else:\n",
    "            print(f\" - Tuyến {i+1} (0.00): [0]\")\n",
    "\n",
    "    # Plot fitness evolution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fitness_per_generation, marker='o', linestyle='-', color='red', markersize=3)\n",
    "    plt.title(f\"MEAX - Fitness qua các thế hệ (m = {m})\")\n",
    "    plt.xlabel(\"Thế hệ\")\n",
    "    plt.ylabel(\"Max route length (fitness)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NSGA-II không phải là lựa chọn tối ưu cho bài toán mTSP.\n",
    "1. Tính bất ổn định cao: Tất cả 3 biểu đồ đều cho thấy dao động mạnh và không có xu hướng hội tụ rõ ràng\n",
    "2. Tốc độ hội tụ chậm: Sau 500 thế hệ vẫn chưa đạt được trạng thái ổn định\n",
    "3. NSGA-II được thiết kế cho đa mục tiêu, nhưng mTSP có cấu trúc đặc biệt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
